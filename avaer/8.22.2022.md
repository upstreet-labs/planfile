- many new AIs deployed over the weekend
- merged new party system/character switching
  - now up to 3 characters are supported (plus ability to interact with them)
- design review for character death
- had to do a few more rounds of reverts because a team member accidentally squashed the wrong side of a merge, destroying history; thank goodness I have experience messing up git repos in past teams :(
- scalable multiplayer backend work was kicked off; fingers crossed
- stable diffusion AI for image synthesis
  - new metaversefile `txt2img` method allows for synthesis of images based on description
    - this allows for synthesis of items, storyboard
  - new metaversefile `img2img` method for remixing images and returning a new version
- clip AI for image semantic processing
  - new metaversefile `img2txt` method allows for describing images (and more importantly scenes); NPCs can now literally have virtual eyes in the world. the plan is to integrate this with the lore pipeline to automate live characters based on visuals without the need to input lore at all, though most accuracy can still be gained. one example that was brought up is if your scene looks spooky, the character will know, and they will be more cautious when exploring.
- diffsound AI for sound synthesis
  - goal is `txt2sound` which can generate an audio buffer for any description, allowing scriptable synthesis of sound effects
  - not done yet, since the repo we are basing it on is "research quality"
  - we managed to get the full audioset and audiocaps datasets, with CLIP features and melspec extraction. this was no small feat since we had to grab it from baidu in over 100 parts, 1TB+ zipped .wav data which was extremely slow to _upload_ to AWS. but baudi netdisk downloader is Windows only
  - so I had to use AWS Windows instance w/ RDP to boot the netdisk downloader, pull the files, then install chrome (challenge since the AWS image is locked down, preventing internet explorer from downloading anything!), then use chrome to download the microsoft WSL + ubuntu install (hard because chrome errors on Microsoft Store store links with no warning, had to figure this out from the js console), then ssh into a parallel box, `rsync -a` the 1TB of data, then extract it on the new machine (twice after accidental deletion because the folder structure was inconsistent and confusing), then grow the AWS disk 3 times due to blowing past the limit, including a change of MBR -> GPT table to support filesystem > 2 TB, then edit the diffsound repo to remove "research style" comments and patch hardcoded cephfs paths before finally being able to generate the melspecs. but I think we're close!
- design work on new scene studio
  - designed the data pipeline for lore and the renderable lore types:
    - entity comment
    - banter
    - loading comment
    - lore exposition
    - rpg dialogue
    - reactions
    - cutscenes
    - quests
  - supports editing object lore with live re-synthesis to see if it's having the intended effect on the character behaviors
  - will set up the writing team to populate the generation baseline flavor so that there is a default of high quiality generation -- but UGC in the scene is mixed in and takes precedence
  - will integrate the scene studio with the current frontend world editor for easier editing of the dynamic scene
- design review for UI refresh; not much structural changes from the current one but it looks a lot cleaner and more consistent overall.